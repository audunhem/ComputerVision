{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Current validation loss: 2.305798292160034  Accuracy: 0.0818\n",
      "Current validation loss: 2.304805028438568  Accuracy: 0.0884\n",
      "Current validation loss: 1.9443772256374359  Accuracy: 0.2934\n",
      "Current validation loss: 1.7901359736919402  Accuracy: 0.3594\n",
      "Current validation loss: 1.590011328458786  Accuracy: 0.4272\n",
      "Current validation loss: 1.4864556968212128  Accuracy: 0.4662\n",
      "Current validation loss: 1.357591938972473  Accuracy: 0.5176\n",
      "Current validation loss: 1.3081365764141082  Accuracy: 0.5422\n",
      "Current validation loss: 1.2315896093845367  Accuracy: 0.5712\n",
      "Current validation loss: 1.161246693134308  Accuracy: 0.594\n",
      "Current validation loss: 1.1200315117836  Accuracy: 0.613\n",
      "Current validation loss: 1.1372531831264496  Accuracy: 0.5978\n",
      "Current validation loss: 1.1011845022439957  Accuracy: 0.6164\n",
      "Current validation loss: 0.9993819952011108  Accuracy: 0.6558\n",
      "Current validation loss: 0.9776435494422913  Accuracy: 0.6526\n",
      "Current validation loss: 0.9459814131259918  Accuracy: 0.672\n",
      "Current validation loss: 0.9556258291006088  Accuracy: 0.6734\n",
      "Current validation loss: 0.8877533227205276  Accuracy: 0.6898\n",
      "Current validation loss: 0.9459479629993439  Accuracy: 0.6774\n",
      "Current validation loss: 0.8533397883176803  Accuracy: 0.7114\n",
      "Current validation loss: 0.8330478876829147  Accuracy: 0.7184\n",
      "Current validation loss: 0.9057572185993195  Accuracy: 0.704\n",
      "Current validation loss: 0.8816332072019577  Accuracy: 0.7062\n",
      "Current validation loss: 0.8722075134515762  Accuracy: 0.7062\n",
      "Current validation loss: 0.8363005250692368  Accuracy: 0.724\n",
      "Current validation loss: 0.9839256823062896  Accuracy: 0.69\n",
      "Current validation loss: 0.8897776216268539  Accuracy: 0.711\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from dataloaders import load_cifar10\n",
    "from utils import to_cuda, compute_loss_and_accuracy\n",
    "\n",
    "\n",
    "class ExampleModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_channels,\n",
    "                 num_classes):\n",
    "        \"\"\"\n",
    "            Is called when model is initialized.\n",
    "            Args:\n",
    "                image_channels. Number of color channels in image (3)\n",
    "                num_classes: Number of classes we want to predict (10)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        num_filters1 = 32  # Set number of filters in first conv layer\n",
    "        num_filters2 = 64  # Set number of filters in second conv layer\n",
    "        num_filters3 = 128  # Set number of filters in third conv layer\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            #First conv layer\n",
    "            nn.Conv2d(\n",
    "                in_channels=image_channels,\n",
    "                out_channels=num_filters1,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            #Second conv layer\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_filters1,\n",
    "                out_channels=num_filters2,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            #Third conv layer\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_filters2,\n",
    "                out_channels=num_filters3,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # The output of feature_extractor will be [batch_size, num_filters, 16, 16]\n",
    "        self.num_output_features = 128*4*4\n",
    "        # Initialize our last fully connected layer\n",
    "        # Inputs all extracted features from the convolutional layers\n",
    "        # Outputs num_classes predictions, 1 for each class.\n",
    "        # There is no need for softmax activation function, as this is\n",
    "        # included with nn.CrossEntropyLoss\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_output_features, 128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the model\n",
    "        Args:\n",
    "            x: Input image, shape: [batch_size, 3, 32, 32]\n",
    "        \"\"\"\n",
    "\n",
    "        # Run image through convolutional layers\n",
    "        x = self.feature_extractor(x)\n",
    "        # Reshape our input to (batch_size, num_output_features)\n",
    "        x = x.view(-1, self.num_output_features)\n",
    "        # Forward pass through the fully-connected layers.\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize our trainer class.\n",
    "        Set hyperparameters, architecture, tracking variables etc.\n",
    "        \"\"\"\n",
    "        # Define hyperparameters\n",
    "        self.epochs = 20\n",
    "        self.batch_size = 256\n",
    "        self.learning_rate = 1e-1\n",
    "        self.early_stop_count = 4\n",
    "\n",
    "        # Architecture\n",
    "\n",
    "        # Since we are doing multi-class classification, we use the CrossEntropyLoss\n",
    "        self.loss_criterion = nn.CrossEntropyLoss()\n",
    "        # Initialize the mode\n",
    "        self.model = ExampleModel(image_channels=3, num_classes=10)\n",
    "        # Transfer model to GPU VRAM, if possible.\n",
    "        self.model = to_cuda(self.model)\n",
    "\n",
    "        # Define our optimizer. SGD = Stochastich Gradient Descent\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(),\n",
    "                                         self.learning_rate)\n",
    "\n",
    "        # Load our dataset\n",
    "        self.dataloader_train, self.dataloader_val, self.dataloader_test = load_cifar10(self.batch_size)\n",
    "\n",
    "        self.validation_check = len(self.dataloader_train) // 2\n",
    "\n",
    "        # Tracking variables\n",
    "        self.VALIDATION_LOSS = []\n",
    "        self.TEST_LOSS = []\n",
    "        self.TRAIN_LOSS = []\n",
    "        self.TRAIN_ACC = []\n",
    "        self.VALIDATION_ACC = []\n",
    "        self.TEST_ACC = []\n",
    "\n",
    "    def validation_epoch(self):\n",
    "        \"\"\"\n",
    "            Computes the loss/accuracy for all three datasets.\n",
    "            Train, validation and test.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        # Compute for training set\n",
    "        train_loss, train_acc = compute_loss_and_accuracy(\n",
    "            self.dataloader_train, self.model, self.loss_criterion\n",
    "        )\n",
    "        self.TRAIN_ACC.append(train_acc)\n",
    "        self.TRAIN_LOSS.append(train_loss)\n",
    "\n",
    "        # Compute for validation set\n",
    "        validation_loss, validation_acc = compute_loss_and_accuracy(\n",
    "            self.dataloader_val, self.model, self.loss_criterion\n",
    "        )\n",
    "        self.VALIDATION_ACC.append(validation_acc)\n",
    "        self.VALIDATION_LOSS.append(validation_loss)\n",
    "        print(\"Current validation loss:\", validation_loss, \" Accuracy:\", validation_acc)\n",
    "        # Compute for testing set\n",
    "        test_loss, test_acc = compute_loss_and_accuracy(\n",
    "            self.dataloader_test, self.model, self.loss_criterion\n",
    "        )\n",
    "        self.TEST_ACC.append(test_acc)\n",
    "        self.TEST_LOSS.append(test_loss)\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "    def should_early_stop(self):\n",
    "        \"\"\"\n",
    "        Checks if validation loss doesn't improve over early_stop_count epochs.\n",
    "        \"\"\"\n",
    "        # Check if we have more than early_stop_count elements in our validation_loss list.\n",
    "        if len(self.VALIDATION_LOSS) < self.early_stop_count:\n",
    "            return False\n",
    "        # We only care about the last [early_stop_count] losses.\n",
    "        relevant_loss = self.VALIDATION_LOSS[-self.early_stop_count:]\n",
    "        previous_loss = relevant_loss[0]\n",
    "        for current_loss in relevant_loss[1:]:\n",
    "            # If the next loss decrease, early stopping criteria is not met.\n",
    "            if current_loss < previous_loss:\n",
    "                return False\n",
    "            previous_loss = current_loss\n",
    "        return True\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the model for [self.epochs] epochs.\n",
    "        \"\"\"\n",
    "        # Track initial loss/accuracy\n",
    "        self.validation_epoch()\n",
    "        for epoch in range(self.epochs):\n",
    "            # Perform a full pass through all the training samples\n",
    "            for batch_it, (X_batch, Y_batch) in enumerate(self.dataloader_train):\n",
    "                # X_batch is the CIFAR10 images. Shape: [batch_size, 3, 32, 32]\n",
    "                # Y_batch is the CIFAR10 image label. Shape: [batch_size]\n",
    "                # Transfer images / labels to GPU VRAM, if possible\n",
    "                X_batch = to_cuda(X_batch)\n",
    "                Y_batch = to_cuda(Y_batch)\n",
    "\n",
    "                # Perform the forward pass\n",
    "                predictions = self.model(X_batch)\n",
    "                # Compute the cross entropy loss for the batch\n",
    "                loss = self.loss_criterion(predictions, Y_batch)\n",
    "\n",
    "                # Backpropagation\n",
    "                loss.backward()\n",
    "\n",
    "                # Gradient descent step\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Reset all computed gradients to 0\n",
    "                self.optimizer.zero_grad()\n",
    "                 # Compute loss/accuracy for all three datasets.\n",
    "                if batch_it % self.validation_check == 0:\n",
    "                    self.validation_epoch()\n",
    "                    # Check early stopping criteria.\n",
    "                    if self.should_early_stop():\n",
    "                        print(\"Early stopping.\")\n",
    "                        return\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer = Trainer()\n",
    "    trainer.train()\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    # Save plots and show them\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Cross Entropy Loss\")\n",
    "    plt.plot(trainer.VALIDATION_LOSS, label=\"Validation loss\")\n",
    "    plt.plot(trainer.TRAIN_LOSS, label=\"Training loss\")\n",
    "    plt.plot(trainer.TEST_LOSS, label=\"Testing Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"plots\", \"final_loss.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(trainer.VALIDATION_ACC, label=\"Validation Accuracy\")\n",
    "    plt.plot(trainer.TRAIN_ACC, label=\"Training Accuracy\")\n",
    "    plt.plot(trainer.TEST_ACC, label=\"Testing Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"plots\", \"final_accuracy.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final test accuracy:\", trainer.TEST_ACC[-trainer.early_stop_count])\n",
    "    print(\"Final validation accuracy:\", trainer.VALIDATION_ACC[-trainer.early_stop_count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
